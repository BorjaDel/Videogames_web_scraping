{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Author: \n",
    "### Borja Delgado GonzÃ¡lez\n",
    "# - Objective: \n",
    "### Project for downloading video game information from the VGChartz website and storing the data in a .csv file or SQL database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries to use in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup, element\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creation of the scraper class for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGameScraper:\n",
    "    def __init__(self, url1, url2, pages):\n",
    "        self.url1 = url1\n",
    "        self.url2 = url2\n",
    "        self.pages = pages\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def scrape(self):\n",
    "        videogame = []\n",
    "        platform = []\n",
    "        editor = []\n",
    "        developer = []\n",
    "        sales_na = []\n",
    "        sales_eu = []\n",
    "        sales_jp = []\n",
    "        sales_others = []\n",
    "        sales_tot = []\n",
    "        release_date = []\n",
    "        genre = []\n",
    "\n",
    "        for page in range(1, self.pages + 1):\n",
    "            surl = self.url1 + str(page) + self.url2\n",
    "            response = self.session.get(surl)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            videogame_tag = list(filter(lambda x: 'href' in x.attrs and x.attrs['href'].startswith('https://www.vgchartz.com/game/'),soup.find_all(\"a\")))\n",
    "\n",
    "            for tag in videogame_tag:\n",
    "                videogame.append(tag.contents[0][:-4])\n",
    "                data = tag.parent.parent.find_all(\"td\")\n",
    "                platform.append(data[3].find(\"img\").attrs[\"alt\"])\n",
    "                editor.append(data[4].string)\n",
    "                developer.append(data[5].string)\n",
    "                sales_na.append(float(data[7].string[:-1]) if not data[7].string.startswith(\"N/A\") else np.nan)\n",
    "                sales_eu.append(float(data[8].string[:-1]) if not data[8].string.startswith(\"N/A\") else np.nan)\n",
    "                sales_jp.append(float(data[9].string[:-1]) if not data[9].string.startswith(\"N/A\") else np.nan)\n",
    "                sales_others.append(float(data[10].string[:-1]) if not data[10].string.startswith(\"N/A\") else np.nan)\n",
    "                sales_tot.append(float(data[6].string[:-1]) if not data[6].string.startswith(\"N/A\") else np.nan)\n",
    "                tag_date = data[11].string.split()[-1]\n",
    "                release_year = np.int32(\"19\" + tag_date) if int(tag_date) >= 80 else np.int32(\"20\" + tag_date)\n",
    "                release_date.append(release_year)\n",
    "                #genre.append(tag.parent.parent.find_all(\"div\", {\"id\": \"gameGenInfoBox\"})[0].find_next_sibling().string)\n",
    "                genre_url = tag.attrs['href']\n",
    "                genre_link = urllib.request.urlopen(genre_url).read()\n",
    "                genre_soup = BeautifulSoup(genre_link, \"html.parser\")\n",
    "      \n",
    "                h2s = genre_soup.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
    "        \n",
    "                genre_tag = element.Tag\n",
    "                for h2 in h2s:\n",
    "                    if h2.string == 'Genre':\n",
    "                        genre_tag = h2\n",
    "                        #print(genre_tag)\n",
    "                genre.append(genre_tag.next_sibling.string)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"videogame\": videogame,\n",
    "            \"platform\": platform,\n",
    "            \"editor\": editor,\n",
    "            \"developer\": developer,\n",
    "            \"sales_na\": sales_na,\n",
    "            \"sales_eu\": sales_eu,\n",
    "            \"sales_jp\": sales_jp,\n",
    "            \"sales_otras\": sales_others,\n",
    "            \"sales_tot\": sales_tot,\n",
    "            \"release\": release_date,\n",
    "            \"genre\": genre\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define url variables\n",
    "    url1 = \"https://www.vgchartz.com/games/games.php?page=\"\n",
    "    url2 = '&results=1000&order=Sales&ownership=Both&direction=DESC&showtotalsales=1' # Here you can change the number after results to change the number of entries displayed by page.\n",
    "    url2 += '&shownasales=1&showpalsales=1&showjapansales=1&showothersales=1&showpublisher=1&showdeveloper=1'\n",
    "    url2 += '&showreleasedate=1&showlastupdate=0&showvgchartzscore=0&showcriticscore=0&showuserscore=0&showshipped=0'\n",
    "    scraper = VideoGameScraper(url1, url2, pages=65) # 65 pages if 1000 entries are displayed in each page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = VideoGameScraper(url1, url2, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Launch it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraper.scrape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Now we can decide wether we want to store the dataset in a .csv..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('videogames_sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Or to store it in a SQL database..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the database\n",
    "conn = sqlite3.connect('videogames_sales_db.sqlite3')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Creation of a table to store the dataframe\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS games (\n",
    "    videogame TEXT,\n",
    "    platform TEXT,\n",
    "    editor TEXT,\n",
    "    developer TEXT,\n",
    "    sales_na FLOAT,\n",
    "    sales_eu FLOAT,\n",
    "    sales_jp FLOAT,\n",
    "    sales_otras FLOAT,\n",
    "    sales_tot FLOAT,\n",
    "    release INTEGER,\n",
    "    genre TEXT\n",
    ")''')\n",
    "\n",
    "# DataFrame into the table\n",
    "df.to_sql('games', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
