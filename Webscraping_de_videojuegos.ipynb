{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# - Autor: \n",
        "### Borja Delgado González\n",
        "# - Objetivo: \n",
        "### Proyecto consistente en descargar la información de videojuegos de la página VGChartz y almacenar los datos en un archivo .csv\n",
        "---\n",
        "##### El proyecto no pretende ser eficiente. Se trata de un proyecto para demostrar cómo obtener datos de una página web.\n",
        "###### A lo largo del código se han implementando algunos \"prints\" para que se pueda ver el elementos por separado."
      ],
      "metadata": {
        "id": "II6XvwBWBzA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Primero importamos las librerías necesarias"
      ],
      "metadata": {
        "id": "2jm2y1VRjYDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU8owPt43WT1"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup, element\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import time\n",
        "from time import sleep\n",
        "from IPython.core.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Creamos las variables necesarias para el proceso"
      ],
      "metadata": {
        "id": "NF91A73QjdrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "url1 = 'https://www.vgchartz.com/games/games.php?page='\n",
        "url2 = '&results=100&order=Sales&ownership=Both&direction=DESC&showtotalsales=1' # despues de results= se puede añadir el número que queramos para modificar el número de resultados por página.\n",
        "url2 += '&shownasales=1&showpalsales=1&showjapansales=1&showothersales=1&showpublisher=1&showdeveloper=1'\n",
        "url2 += '&showreleasedate=1&showlastupdate=0&showvgchartzscore=0&showcriticscore=0&showuserscore=0&showshipped=0'\n",
        "\n",
        "paginas = 62 # 62 es el número de páginas de la tabla si se muestran 100 resultados por página.\n",
        "videojuego = []\n",
        "plataforma = []\n",
        "genero = []\n",
        "editor = []\n",
        "desarrollador = []\n",
        "ventas_na = []\n",
        "ventas_eu = []\n",
        "ventas_jp = []\n",
        "ventas_otras = []\n",
        "ventas_tot = []\n",
        "fecha_salida = []\n",
        "peticiones = 0 # en el código hay implementada una línea que muestra el número de datos (juegos) recogidos. Se inicializa a 0 para poder darle seguimiento al proceso.\n",
        "\n",
        "dict_csv = {\n",
        "    'videojuego': videojuego,\n",
        "    'plataforma': plataforma,\n",
        "    'genero': genero,\n",
        "    'editor': editor,\n",
        "    'desarrollador': desarrollador,\n",
        "    'ventas_na': ventas_na,\n",
        "    'ventas_eu': ventas_eu,\n",
        "    'ventas_jp': ventas_jp,\n",
        "    'ventas_otras': ventas_otras,\n",
        "    'ventas_tot': ventas_tot,\n",
        "    'fecha_salida': fecha_salida\n",
        "    }\n"
      ],
      "metadata": {
        "id": "3-5vcUZ34jbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implementamos el código para el scraping"
      ],
      "metadata": {
        "id": "pwg9mwmbkjDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Establecemos un for loop que va a recorrer el DOM de la página web y localizará los elementos <a> que tengan un enlace.\n",
        "for pagina in range(1, paginas):\n",
        "    surl = url1 + str(pagina) + url2\n",
        "    r = urllib.request.urlopen(surl).read()\n",
        "    soup = BeautifulSoup(r)\n",
        "    \n",
        "    #Almacenamos los elementos en una lista para implementar otro for loop.\n",
        "    etiquetas_videojuegos = list(filter(lambda x: 'href' in x.attrs and x.attrs['href'].startswith('https://www.vgchartz.com/game/'),soup.find_all(\"a\")))\n",
        "    #print(etiquetas_videojuegos)\n",
        "    for etiqueta in etiquetas_videojuegos:\n",
        "      #Le damos seguimiento al proceso mostrando el número de peticiones realizadas.\n",
        "      peticiones += 1\n",
        "      print('Peticiones: {}'.format(peticiones))\n",
        "      clear_output(wait = True)\n",
        "      \n",
        "      #Lo primero que recogemos es el nombre del videojuego.\n",
        "      videojuego.append(etiqueta.contents[0][:-4])\n",
        "      #print(etiqueta.contents)\n",
        "      \n",
        "      #A partir de cada tag, subimos dos niveles en el DOM hasta encontrar la fila de cada elemento de la tabla y poder ir extrayendo los datos uno a uno.\n",
        "      data = etiqueta.parent.parent.find_all(\"td\")\n",
        "\n",
        "      plataforma.append(data[3].find('img').attrs['alt'])\n",
        "      editor.append(data[4].string)\n",
        "      desarrollador.append(data[5].string)\n",
        "\n",
        "      #Las ventas se recogen con el como floats o np.nan si no existe valor para evitar errores.\n",
        "      ventas_na.append(\n",
        "          float(data[7].string[:-1]) if\n",
        "          not data[7].string.startswith(\"N/A\") else np.nan)\n",
        "      ventas_eu.append(\n",
        "          float(data[8].string[:-1]) if\n",
        "          not data[8].string.startswith(\"N/A\") else np.nan)\n",
        "      ventas_jp.append(\n",
        "          float(data[9].string[:-1]) if\n",
        "          not data[9].string.startswith(\"N/A\") else np.nan)\n",
        "      ventas_otras.append(\n",
        "          float(data[10].string[:-1]) if\n",
        "          not data[10].string.startswith(\"N/A\") else np.nan)\n",
        "      ventas_tot.append(\n",
        "          float(data[6].string[:-1]) if\n",
        "          not data[6].string.startswith(\"N/A\") else np.nan)\n",
        "      \n",
        "      #Se para el proceso para evitar el error 429.\n",
        "      sleep(randint(1,3))\n",
        "\n",
        "      #Dividimos el elemento \"Release Date\" de la página para quedarnos sólo con el año, compuesto por dos dígitos y lo almacenamos en una variable.\n",
        "      lanzamiento = data[11].string.split()[-1]\n",
        "      \n",
        "      if lanzamiento.startswith('N/A'):\n",
        "          lanzamiento.append('N/A')\n",
        "      else:\n",
        "          if int(lanzamiento) >= 80:\n",
        "              anyo_lanzamiento = np.int32(\"19\" + lanzamiento)\n",
        "          else:\n",
        "              anyo_lanzamiento = np.int32(\"20\" + lanzamiento)\n",
        "          fecha_salida.append(anyo_lanzamiento)\n",
        "      \n",
        "      #El género del juego no aparece en la tabla. Tenemos que buscarlo dentro de la página del juego.\n",
        "      #Identificamos el link para entrar a la página y dentro de la nueva página identificamos dónde se encuentra el género del juego.\n",
        "      #Dentro del div \"gameGenInfoBox\" hay 3 etiquetas <h2> siendo una de ellas el género. Lo localizamos y lo almacenamos en una variable.\n",
        "      #Una vez localizado el <h2> del género, recogemos el dato de la siguiente etiqueta\n",
        "      url_genero = etiqueta.attrs['href']\n",
        "      link_genero = urllib.request.urlopen(url_genero).read()\n",
        "      soup_genero = BeautifulSoup(link_genero, \"html.parser\")\n",
        "     \n",
        "      h2s = soup_genero.find(\"div\", {\"id\": \"gameGenInfoBox\"}).find_all('h2')\n",
        "      \n",
        "      etiqueta_genero = element.Tag\n",
        "      for h2 in h2s:\n",
        "          if h2.string == 'Genre':\n",
        "              etiqueta_genero = h2\n",
        "              #print(etiqueta_genero)\n",
        "      genero.append(etiqueta_genero.next_sibling.string)\n",
        "      #print(etiqueta_genero.next_sibling.string)\n",
        "\n"
      ],
      "metadata": {
        "id": "4_dxw3-aSF8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Creamos un csv a partir de las listas de datos"
      ],
      "metadata": {
        "id": "TZ9nKNRExePe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dict_csv)\n",
        "\n",
        "df.to_csv('ventas_videojuegos.csv')"
      ],
      "metadata": {
        "id": "I1aJybJxxpej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}